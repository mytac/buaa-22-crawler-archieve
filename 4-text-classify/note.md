## 1. 简述文本分类的一般流程

1. 文本预处理：比如先对文本进行分词、去除停用词、词形规范化等
2. 特征选择和特征提取：高维特征中存在噪声，要进行特征提取，选择最有代表性的词作为文本的特征向量
3. 文本表示：将文本使用空间向量模型、布尔模型、概率检索模型表示
4. 分类器参数学习：使用 Bayes、KNN、SVM 等方法进行分类，并调整模型参数
5. 分类：用训练好的分类器对待分类样本的归属类别进行计算
6. 分类器性能评估：使用一些指标，对分类器的性能进行评估，如：准确率、召回率、F 值等等。

![流程](https://s1.ax1x.com/2022/12/13/z56MRg.png)

## 2. 谈谈你对三种分类器(朴素 Bayes、KNN 和 SVM)的看法。(注：无需推导公式 )

### 1. Bayes

朴素贝叶斯方法是一组基于贝叶斯定理与特征条件独立假设的监督学习算法，在给定类变量值的情况下，朴素假设每对特征之间存在条件独立性。朴素贝叶斯原理简单，需要关注的参数比较少，也很容易实现。

朴素贝叶斯最擅长的领域是文本分析，包括：文本分类、垃圾邮件过滤、情感分析等。

公式如下：

$P(B|A)= \frac{P(A|B)P(B)}{P(A)}$

[文本分类（朴素贝叶斯分类）介绍](https://blog.csdn.net/qq_42374697/article/details/113413359)

### 2.KNN （K-Nearest Neighbors）

KNN 简单说就是，要看一个新数据是什么类别，就看他的邻居属于什么类，他的邻居属于什么类别的多，他就属于什么类别。

k 指的是邻居数，比如：k 等于 3，就是通过离的最近的 3 个样本来判断新数据的类别。k 的取值十分重要，如果 k 值小，很容易受个例影响，k 值过大，则会受到较远的特殊数据的影响。

计算距离时，可以用曼哈顿距离，或是欧氏距离。

KNN 主要应用于文本分词、统计词频后判断文章的类别、或应用于推荐算法等。

KNN 的缺点：要先算一遍新样本与所有样本之间的距离，按由近到远顺序排列后，再按 k 值确定分类，所以数据越多，KNN 的计算量越大，效率越低，很难应用于较大的数据集中。

### 3. SVM（Support Vector Machine）

简单来说，SVM 的思路是尽可能构造出一个超平面，使不同类的数据分开，且不同类数据到该超平面的距离之和尽可能大。

划分方法就是，找到能让所有样本分类可信程度最高的那条线，不必计算所有的距离，只要找到线附近的样本，让它们与线的距离越远越好，距离线最近的样本为支持向量，距离线最近的向量与线的距离叫分类间隔。（样本在无法使用直线划分的情况时，可通过一定的变换，将其映射到一个能用直线区分的空间。）

优点：svm 对样本依赖小，不会过拟合，小样本也能取得不错的效果。

SVM 主要应用于：本文分类、垃圾邮件识别、图像分类等，应用比较广泛。
